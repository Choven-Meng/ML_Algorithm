朴素贝叶斯是使用概率论来分类的算法(选取概率大的情况进行分类)。其中 **朴素** ：各特征条件独立；**贝叶斯**：根据贝叶斯定理。     
当要根据多个特征而非一个特征对数据进行分类的时候，我们可以假设这些特征相互独立（或者先假设相互独立），然后利用条件概率乘
法法则得到每一个分类的概率， 然后选择概率最大的那个作为机器的判定。    

**朴素** 的见解：之所以叫朴素贝叶斯，因为它简单、易于操作，基于特征独立性假设，假设各个特征不会相互影响，这样就大大减小了计算概率的难度。  

贝叶斯条件概率公式：  
  **P(A|B) = P(AB)/P(B) = P(B|A)P(A)/P(B)**

## 朴素贝叶斯的参数估计

1、极大似然估计

2、贝叶斯估计

用极大似然估计可能会出现所要估计的概率值为0的情况，解决这一问题的方法是采用贝叶斯估计。  


朴素贝叶斯最常见的分类应用是对文档进行分类，因此，最常见的特征条件是文档中，出现词汇的情况，通常将词汇出现的特征条件用词向量 ω表示，由多个数值组成，
数值的个数和训练样本集中的词汇表个数相同。



**优点：**

1、朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。  
2、对小规模的数据表现很好，能个处理多分类任务，适合增量式训练，尤其是数据量超出内存时，我们可以一批批的去增量训练。  
3、对缺失数据不太敏感，算法也比较简单，常用于文本分类。  

**缺点：**

1、理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型假设属性之间相互独立，这个假设在实际应用中
往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之
类的算法通过考虑部分关联性适度改进。  
2、需要知道先验概率，且先验概率很多时候取决于假设，假设的模型可以有很多种，因此在某些时候会由于假设的先验模型的原因导致预测效果不佳。  
3、由于我们是通过先验和数据来决定后验的概率从而决定分类，所以分类决策存在一定的错误率。对输入数据的表达形式很敏感。  
